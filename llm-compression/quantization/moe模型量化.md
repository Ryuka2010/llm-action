



Mixture Compressor for Mixture-of-Experts LLMs Gains More

MoEQuant: Enhancing Quantization for Mixture-of-Experts Large Language Models via Expert-Balanced Sampling and Affinity Guidance
